{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaborative Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "# import pandas_datareader as web\n",
    "#from sklearn.tree import DecisionTreeRegressor\n",
    "#from sklearn.linear_mode\n",
    "#import LinearRegression\n",
    "#from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential\n",
    "from keras import Model\n",
    "from keras.layers import Dense, LSTM, Dropout, Concatenate\n",
    "from keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#plt.style.use('fivethirtyeight')\n",
    "#plt.style.use('fivethirtyeight')\n",
    "plt.style.use('seaborn-v0_8-dark')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Stocks dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>low</th>\n",
       "      <th>high</th>\n",
       "      <th>volume</th>\n",
       "      <th>close</th>\n",
       "      <th>Name</th>\n",
       "      <th>Date</th>\n",
       "      <th>Positve</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Total</th>\n",
       "      <th>NeutralPos</th>\n",
       "      <th>NeutralNeg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10/2/2017</td>\n",
       "      <td>964.00</td>\n",
       "      <td>952.1201</td>\n",
       "      <td>967.305</td>\n",
       "      <td>2415846</td>\n",
       "      <td>959.19</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>10/2/2017</td>\n",
       "      <td>37.088734</td>\n",
       "      <td>7.577268</td>\n",
       "      <td>55.333998</td>\n",
       "      <td>1003</td>\n",
       "      <td>37.088734</td>\n",
       "      <td>14.260219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10/3/2017</td>\n",
       "      <td>958.00</td>\n",
       "      <td>950.3700</td>\n",
       "      <td>963.690</td>\n",
       "      <td>2643484</td>\n",
       "      <td>957.10</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>10/3/2017</td>\n",
       "      <td>38.159879</td>\n",
       "      <td>11.085973</td>\n",
       "      <td>50.754148</td>\n",
       "      <td>1326</td>\n",
       "      <td>38.159879</td>\n",
       "      <td>22.348774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10/4/2017</td>\n",
       "      <td>954.21</td>\n",
       "      <td>954.0500</td>\n",
       "      <td>967.790</td>\n",
       "      <td>2460721</td>\n",
       "      <td>965.45</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>10/4/2017</td>\n",
       "      <td>36.168582</td>\n",
       "      <td>10.727969</td>\n",
       "      <td>53.103448</td>\n",
       "      <td>1305</td>\n",
       "      <td>36.168582</td>\n",
       "      <td>19.641470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10/5/2017</td>\n",
       "      <td>970.00</td>\n",
       "      <td>969.6400</td>\n",
       "      <td>981.510</td>\n",
       "      <td>3119487</td>\n",
       "      <td>980.85</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>10/5/2017</td>\n",
       "      <td>47.939017</td>\n",
       "      <td>7.227555</td>\n",
       "      <td>44.833427</td>\n",
       "      <td>1771</td>\n",
       "      <td>47.939017</td>\n",
       "      <td>24.411076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10/6/2017</td>\n",
       "      <td>975.64</td>\n",
       "      <td>975.6400</td>\n",
       "      <td>995.750</td>\n",
       "      <td>3719840</td>\n",
       "      <td>989.58</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>10/6/2017</td>\n",
       "      <td>34.628045</td>\n",
       "      <td>11.586570</td>\n",
       "      <td>53.785385</td>\n",
       "      <td>1519</td>\n",
       "      <td>34.628045</td>\n",
       "      <td>19.818134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>3/5/2018</td>\n",
       "      <td>1494.24</td>\n",
       "      <td>1481.0000</td>\n",
       "      <td>1525.380</td>\n",
       "      <td>5233934</td>\n",
       "      <td>1523.61</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>3/5/2018</td>\n",
       "      <td>38.274182</td>\n",
       "      <td>7.794015</td>\n",
       "      <td>53.931802</td>\n",
       "      <td>1437</td>\n",
       "      <td>38.274182</td>\n",
       "      <td>15.879162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>3/6/2018</td>\n",
       "      <td>1533.20</td>\n",
       "      <td>1528.0000</td>\n",
       "      <td>1542.130</td>\n",
       "      <td>4561718</td>\n",
       "      <td>1537.64</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>3/6/2018</td>\n",
       "      <td>45.234604</td>\n",
       "      <td>6.818182</td>\n",
       "      <td>47.947214</td>\n",
       "      <td>1364</td>\n",
       "      <td>45.234604</td>\n",
       "      <td>20.887916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>3/7/2018</td>\n",
       "      <td>1526.52</td>\n",
       "      <td>1522.5100</td>\n",
       "      <td>1545.900</td>\n",
       "      <td>4174123</td>\n",
       "      <td>1545.00</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>3/7/2018</td>\n",
       "      <td>38.167260</td>\n",
       "      <td>9.786477</td>\n",
       "      <td>52.046263</td>\n",
       "      <td>1124</td>\n",
       "      <td>38.167260</td>\n",
       "      <td>19.757162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>3/8/2018</td>\n",
       "      <td>1550.00</td>\n",
       "      <td>1545.2500</td>\n",
       "      <td>1554.880</td>\n",
       "      <td>3512528</td>\n",
       "      <td>1551.86</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>3/8/2018</td>\n",
       "      <td>37.221728</td>\n",
       "      <td>8.726625</td>\n",
       "      <td>54.051647</td>\n",
       "      <td>1123</td>\n",
       "      <td>37.221728</td>\n",
       "      <td>16.691926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>3/9/2018</td>\n",
       "      <td>1563.50</td>\n",
       "      <td>1559.0800</td>\n",
       "      <td>1578.940</td>\n",
       "      <td>4417059</td>\n",
       "      <td>1578.89</td>\n",
       "      <td>AMZN</td>\n",
       "      <td>3/9/2018</td>\n",
       "      <td>39.465570</td>\n",
       "      <td>10.996917</td>\n",
       "      <td>49.537513</td>\n",
       "      <td>973</td>\n",
       "      <td>39.465570</td>\n",
       "      <td>23.476353</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>109 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          date     open        low      high   volume    close  Name  \\\n",
       "0    10/2/2017   964.00   952.1201   967.305  2415846   959.19  AMZN   \n",
       "1    10/3/2017   958.00   950.3700   963.690  2643484   957.10  AMZN   \n",
       "2    10/4/2017   954.21   954.0500   967.790  2460721   965.45  AMZN   \n",
       "3    10/5/2017   970.00   969.6400   981.510  3119487   980.85  AMZN   \n",
       "4    10/6/2017   975.64   975.6400   995.750  3719840   989.58  AMZN   \n",
       "..         ...      ...        ...       ...      ...      ...   ...   \n",
       "104   3/5/2018  1494.24  1481.0000  1525.380  5233934  1523.61  AMZN   \n",
       "105   3/6/2018  1533.20  1528.0000  1542.130  4561718  1537.64  AMZN   \n",
       "106   3/7/2018  1526.52  1522.5100  1545.900  4174123  1545.00  AMZN   \n",
       "107   3/8/2018  1550.00  1545.2500  1554.880  3512528  1551.86  AMZN   \n",
       "108   3/9/2018  1563.50  1559.0800  1578.940  4417059  1578.89  AMZN   \n",
       "\n",
       "          Date    Positve   Negative    Neutral  Total  NeutralPos  NeutralNeg  \n",
       "0    10/2/2017  37.088734   7.577268  55.333998   1003   37.088734   14.260219  \n",
       "1    10/3/2017  38.159879  11.085973  50.754148   1326   38.159879   22.348774  \n",
       "2    10/4/2017  36.168582  10.727969  53.103448   1305   36.168582   19.641470  \n",
       "3    10/5/2017  47.939017   7.227555  44.833427   1771   47.939017   24.411076  \n",
       "4    10/6/2017  34.628045  11.586570  53.785385   1519   34.628045   19.818134  \n",
       "..         ...        ...        ...        ...    ...         ...         ...  \n",
       "104   3/5/2018  38.274182   7.794015  53.931802   1437   38.274182   15.879162  \n",
       "105   3/6/2018  45.234604   6.818182  47.947214   1364   45.234604   20.887916  \n",
       "106   3/7/2018  38.167260   9.786477  52.046263   1124   38.167260   19.757162  \n",
       "107   3/8/2018  37.221728   8.726625  54.051647   1123   37.221728   16.691926  \n",
       "108   3/9/2018  39.465570  10.996917  49.537513    973   39.465570   23.476353  \n",
       "\n",
       "[109 rows x 14 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo_df = pd.read_csv('./Combining Stock and Twitter Data/MyDrive/AmazonStock_Sentiment_6M.csv');\n",
    "demo_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing general user's decisions in the past"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_decisions_list = []\n",
    "df_decisions_list.append({'df': pd.read_csv('./amazon_stock_trades.csv'), 'comp': 'AMZN'})\n",
    "df_decisions_list.append({'df': pd.read_csv('./apple_stock_trades.csv'), 'comp': 'AAPL'})\n",
    "df_decisions_list.append({'df': pd.read_csv('./cisco_stock_trades.csv'), 'comp': 'CSCO'})\n",
    "df_decisions_list.append({'df': pd.read_csv('./ibm_stock_trades.csv'), 'comp': 'IBM'})\n",
    "df_decisions_list.append({'df': pd.read_csv('./jnj_stock_trades.csv'), 'comp': 'JNJ'})\n",
    "df_decisions_list.append({'df': pd.read_csv('./jnpr_stock_trades.csv'), 'comp': 'JNPR'})\n",
    "df_decisions_list.append({'df': pd.read_csv('./msft_stock_trades.csv'), 'comp': 'MSFT'})\n",
    "df_decisions_list.append({'df': pd.read_csv('./orcl_stock_trades.csv'), 'comp': 'ORCL'})\n",
    "df_decisions_list.append({'df': pd.read_csv('./pfizer_stock_trades.csv'), 'comp': 'PFIZER'})\n",
    "df_decisions_list.append({'df': pd.read_csv('./tgt_stock_trades.csv'), 'comp': 'TGT'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalising the decisions based on companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale each df \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "columns_to_exclude = ['Sector of stock', 'Buy/Sell/Keep']\n",
    "columns_to_normalize = ['Current Value of Stock', 'Expected Value of Stock', 'Error in expected value of stock', 'Percentage of portfolio', 'Percentage of sector', 'Positive', 'Negative', 'Neutral', 'Total', 'Neutral_Pos', 'Neutral_Neg']\n",
    "scalers_decisions = []\n",
    "for i in range(len(df_decisions_list)):\n",
    "    scaler = MinMaxScaler()\n",
    "    normalized_values = scaler.fit_transform(df_decisions_list[i]['df'][columns_to_normalize])\n",
    "    normalized_df = pd.DataFrame(normalized_values, columns=columns_to_normalize)\n",
    "    scalers_decisions.append({'scaler': scaler, 'comp': df_decisions_list[i]['comp']})\n",
    "\n",
    "    # Concatenate the normalized DataFrame with the excluded column\n",
    "    df_decisions_list[i]['df'] = pd.concat([normalized_df, df_decisions_list[i]['df'][columns_to_exclude]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'scaler': MinMaxScaler(), 'comp': 'AMZN'},\n",
       " {'scaler': MinMaxScaler(), 'comp': 'AAPL'},\n",
       " {'scaler': MinMaxScaler(), 'comp': 'CSCO'},\n",
       " {'scaler': MinMaxScaler(), 'comp': 'IBM'},\n",
       " {'scaler': MinMaxScaler(), 'comp': 'JNJ'},\n",
       " {'scaler': MinMaxScaler(), 'comp': 'JNPR'},\n",
       " {'scaler': MinMaxScaler(), 'comp': 'MSFT'},\n",
       " {'scaler': MinMaxScaler(), 'comp': 'ORCL'},\n",
       " {'scaler': MinMaxScaler(), 'comp': 'PFIZER'},\n",
       " {'scaler': MinMaxScaler(), 'comp': 'TGT'}]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalers_decisions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing 6 months stock data of each company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scalers for stock data\n",
    "\n",
    "# create main_df for each company stock data\n",
    "main_df = []\n",
    "main_df.append({'df': pd.read_csv('./Combining Stock and Twitter Data/MyDrive/AmazonStock_Sentiment_6M.csv').drop(['date','Date','Name'],axis=1), 'comp': 'AMZN'})\n",
    "main_df.append({'df': pd.read_csv('./Combining Stock and Twitter Data/MyDrive/AAPLStock_sentiment_6M.csv').drop(['date','Date','Name'],axis=1), 'comp': 'AAPL'})\n",
    "main_df.append({'df': pd.read_csv('./Combining Stock and Twitter Data/MyDrive/CSCOStock_Sentiment_6M.csv').drop(['date','Date','Name'],axis=1), 'comp': 'CSCO'})\n",
    "main_df.append({'df': pd.read_csv('./Combining Stock and Twitter Data/MyDrive/IBMStock_Sentiment_6M.csv').drop(['date','Date','Name'],axis=1), 'comp': 'IBM'})\n",
    "main_df.append({'df': pd.read_csv('./Combining Stock and Twitter Data/MyDrive/JNJStock_Sentiment_6M.csv').drop(['date','Date','Name'],axis=1), 'comp': 'JNJ'})\n",
    "main_df.append({'df': pd.read_csv('./Combining Stock and Twitter Data/MyDrive/JNPRStock_Sentiment_6M.csv').drop(['date','Date','Name'],axis=1), 'comp': 'JNPR'})\n",
    "main_df.append({'df': pd.read_csv('./Combining Stock and Twitter Data/MyDrive/MSFTStock_Sentiment_6M.csv').drop(['date','Date','Name'],axis=1), 'comp': 'MSFT'})\n",
    "main_df.append({'df': pd.read_csv('./Combining Stock and Twitter Data/MyDrive/ORCLStock_Sentiment_6M.csv').drop(['date','Date','Name'],axis=1), 'comp': 'ORCL'})\n",
    "main_df.append({'df': pd.read_csv('./Combining Stock and Twitter Data/MyDrive/PfizerStock_Sentiment_6M.csv').drop(['date','Date','Name'],axis=1), 'comp': 'PFIZER'})\n",
    "main_df.append({'df': pd.read_csv('./Combining Stock and Twitter Data/MyDrive/TGTStock_Sentiment_6M.csv').drop(['date','Date','Name'],axis=1), 'comp': 'TGT'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the diff and exp column\n",
    "for i in main_df:\n",
    "    i['df']['diff']=i['df']['high']-i['df']['low']\n",
    "for i in main_df:\n",
    "    i['df']['exp']=(i['df']['open']+i['df']['close'])/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalising the stocks data by company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalers_stock = []\n",
    "for i in range(len(main_df)):\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    main_df[i]['df'][main_df[i]['df'].columns] = scaler.fit_transform(main_df[i]['df'][main_df[i]['df'].columns])\n",
    "    scalers_stock.append({'scaler': scaler, 'comp': main_df[i]['comp']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.01690875490077537 0.0 0.0573411800211275 ... 0.2889154068034872 'IT'\n",
      "  'Keep']\n",
      " [0.006545881621444094 0.003842394418416717 0.06051003470650517 ...\n",
      "  0.4996072102743184 'IT' 'Keep']\n",
      " [0.0 0.030124035188243692 0.04640108646446504 ... 0.42908697933553197\n",
      "  'IT' 'Buy']\n",
      " ...\n",
      " [0.8417116742833404 0.7736249734550866 0.9428571428571434 ...\n",
      "  0.37337504235759883 'Consumer Discretionary' 'Keep']\n",
      " [0.8201080182800169 0.6982374177107671 0.2527472527472538 ...\n",
      "  0.5026178016456893 'Consumer Discretionary' 'Sell']\n",
      " [0.6875778977980893 0.6704183478445533 0.44395604395604266 ...\n",
      "  0.3476663784289607 'Consumer Discretionary' 'Keep']]\n"
     ]
    }
   ],
   "source": [
    "dataset = []\n",
    "for i in df_decisions_list:\n",
    "    dataset.append(i['df'].values)\n",
    "dataset = np.concatenate(dataset, axis = 0)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenating the stocks data to a single CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('stock_decisions.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(['Current Value of Stock', 'Expected Value of Stock', 'Error in expected value of stock', 'Percentage of portfolio', 'Percentage of sector', 'Positive', 'Negative', 'Neutral', 'Total', 'Neutral_Pos', 'Neutral_Neg', 'Sector of stock','Buy/Sell/Keep'])\n",
    "    writer.writerows(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Current Value of Stock</th>\n",
       "      <th>Expected Value of Stock</th>\n",
       "      <th>Error in expected value of stock</th>\n",
       "      <th>Percentage of portfolio</th>\n",
       "      <th>Percentage of sector</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Total</th>\n",
       "      <th>Neutral_Pos</th>\n",
       "      <th>Neutral_Neg</th>\n",
       "      <th>Sector of stock</th>\n",
       "      <th>Buy/Sell/Keep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.016909</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.057341</td>\n",
       "      <td>0.747695</td>\n",
       "      <td>0.353394</td>\n",
       "      <td>0.634112</td>\n",
       "      <td>0.393651</td>\n",
       "      <td>0.209993</td>\n",
       "      <td>0.363674</td>\n",
       "      <td>0.354623</td>\n",
       "      <td>0.288915</td>\n",
       "      <td>IT</td>\n",
       "      <td>Keep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.006546</td>\n",
       "      <td>0.003842</td>\n",
       "      <td>0.060510</td>\n",
       "      <td>0.875622</td>\n",
       "      <td>0.132926</td>\n",
       "      <td>0.659470</td>\n",
       "      <td>0.618285</td>\n",
       "      <td>0.282692</td>\n",
       "      <td>0.270249</td>\n",
       "      <td>0.399351</td>\n",
       "      <td>0.499607</td>\n",
       "      <td>IT</td>\n",
       "      <td>Keep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030124</td>\n",
       "      <td>0.046401</td>\n",
       "      <td>0.038742</td>\n",
       "      <td>0.334798</td>\n",
       "      <td>0.612328</td>\n",
       "      <td>0.595365</td>\n",
       "      <td>0.277965</td>\n",
       "      <td>0.318172</td>\n",
       "      <td>0.316199</td>\n",
       "      <td>0.429087</td>\n",
       "      <td>IT</td>\n",
       "      <td>Buy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.027272</td>\n",
       "      <td>0.042233</td>\n",
       "      <td>0.108571</td>\n",
       "      <td>0.334854</td>\n",
       "      <td>0.926111</td>\n",
       "      <td>0.890981</td>\n",
       "      <td>0.371262</td>\n",
       "      <td>0.382849</td>\n",
       "      <td>0.149471</td>\n",
       "      <td>0.807705</td>\n",
       "      <td>0.553326</td>\n",
       "      <td>IT</td>\n",
       "      <td>Sell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.037013</td>\n",
       "      <td>0.058251</td>\n",
       "      <td>0.039837</td>\n",
       "      <td>0.165370</td>\n",
       "      <td>0.620705</td>\n",
       "      <td>0.575857</td>\n",
       "      <td>0.650335</td>\n",
       "      <td>0.326131</td>\n",
       "      <td>0.332083</td>\n",
       "      <td>0.251870</td>\n",
       "      <td>0.433689</td>\n",
       "      <td>IT</td>\n",
       "      <td>Buy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Current Value of Stock  Expected Value of Stock  \\\n",
       "0                0.016909                 0.000000   \n",
       "1                0.006546                 0.003842   \n",
       "2                0.000000                 0.030124   \n",
       "3                0.027272                 0.042233   \n",
       "4                0.037013                 0.058251   \n",
       "\n",
       "   Error in expected value of stock  Percentage of portfolio  \\\n",
       "0                          0.057341                 0.747695   \n",
       "1                          0.060510                 0.875622   \n",
       "2                          0.046401                 0.038742   \n",
       "3                          0.108571                 0.334854   \n",
       "4                          0.039837                 0.165370   \n",
       "\n",
       "   Percentage of sector  Positive  Negative   Neutral     Total  Neutral_Pos  \\\n",
       "0              0.353394  0.634112  0.393651  0.209993  0.363674     0.354623   \n",
       "1              0.132926  0.659470  0.618285  0.282692  0.270249     0.399351   \n",
       "2              0.334798  0.612328  0.595365  0.277965  0.318172     0.316199   \n",
       "3              0.926111  0.890981  0.371262  0.382849  0.149471     0.807705   \n",
       "4              0.620705  0.575857  0.650335  0.326131  0.332083     0.251870   \n",
       "\n",
       "   Neutral_Neg Sector of stock Buy/Sell/Keep  \n",
       "0     0.288915              IT          Keep  \n",
       "1     0.499607              IT          Keep  \n",
       "2     0.429087              IT           Buy  \n",
       "3     0.553326              IT          Sell  \n",
       "4     0.433689              IT           Buy  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_decisions = pd.read_csv('./stock_decisions.csv');\n",
    "df_decisions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_decisions.drop('Sector of stock', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taking Input from the user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Percentage of portfolio': 0.5,\n",
       "  'Percentage of sector': 15.56,\n",
       "  'Sector of Stock': 'IT',\n",
       "  'comp': 'AMZN'},\n",
       " {'Percentage of portfolio': 4.5,\n",
       "  'Percentage of sector': 7.8,\n",
       "  'Sector of Stock': 'IT',\n",
       "  'comp': 'MSFT'},\n",
       " {'Percentage of portfolio': 7.5,\n",
       "  'Percentage of sector': 18.26,\n",
       "  'Sector of Stock': 'Health',\n",
       "  'comp': 'AAPL'},\n",
       " {'Percentage of portfolio': 16.5,\n",
       "  'Percentage of sector': 10.26,\n",
       "  'Sector of Stock': 'Health',\n",
       "  'comp': 'PFIZER'}]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = []\n",
    "\n",
    "todays_date = '1/5/2018'\n",
    "list_of_stocks = []\n",
    "list_of_stocks.append({'Percentage of portfolio': 0.5, 'Percentage of sector': 15.56, 'Sector of Stock': 'IT', 'comp': 'AMZN'});\n",
    "list_of_stocks.append({'Percentage of portfolio': 4.5, 'Percentage of sector': 7.8, 'Sector of Stock': 'IT', 'comp': 'MSFT'});\n",
    "list_of_stocks.append({'Percentage of portfolio': 7.5, 'Percentage of sector': 18.26, 'Sector of Stock': 'Health', 'comp': 'AAPL'});\n",
    "list_of_stocks.append({'Percentage of portfolio': 16.5, 'Percentage of sector': 10.26, 'Sector of Stock': 'Health', 'comp': 'PFIZER'});\n",
    "list_of_stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialsing the LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.losses import MeanSquaredLogarithmicError, MeanSquaredError\n",
    "from keras.layers import Dense, LSTM, Dropout, Concatenate, BatchNormalization\n",
    "from tensorflow.keras.saving import register_keras_serializable\n",
    "@register_keras_serializable(package=\"MyLoss\")\n",
    "def MyLoss(y_true, y_pred):\n",
    "    msle = MeanSquaredLogarithmicError()(y_true[:,0], y_pred[:,0])\n",
    "    mse = MeanSquaredError()(y_true[:,1],y_pred[:,1])\n",
    "    return  msle + mse\n",
    "\n",
    "@register_keras_serializable(package='MyModel')\n",
    "class MyModel(Model):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.lstm1 = LSTM(units=50, return_sequences=True,\n",
    "                          input_shape=[None,30,13])\n",
    "        self.bn1 = BatchNormalization()\n",
    "        self.dropout1 = Dropout(0.2)\n",
    "\n",
    "        self.lstm2 = LSTM(units=60, return_sequences=True)\n",
    "        self.bn2 = BatchNormalization()\n",
    "        self.dropout2 = Dropout(0.3)\n",
    "\n",
    "        self.lstm3 = LSTM(units=70, return_sequences=True)\n",
    "        self.bn3 = BatchNormalization()\n",
    "        self.dropout3 = Dropout(0.4)\n",
    "\n",
    "        self.lstm4 = LSTM(units=80)\n",
    "        self.bn4 = BatchNormalization()\n",
    "        self.dropout4 = Dropout(0.5)\n",
    "\n",
    "        self.dense1_1 = Dense(20)\n",
    "        self.dense2_1 = Dense(1)\n",
    "\n",
    "        self.dense1_2 = Dense(20)\n",
    "        self.dense2_2 = Dense(1)\n",
    "        self.concat = Concatenate(axis=-1)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        enc = self.lstm1(inputs)\n",
    "        enc = self.bn1(enc)\n",
    "        enc = self.dropout1(enc)\n",
    "\n",
    "        enc = self.lstm2(enc)\n",
    "        enc = self.bn2(enc)\n",
    "        enc = self.dropout2(enc)\n",
    "\n",
    "        enc = self.lstm3(enc)\n",
    "        enc = self.bn3(enc)\n",
    "        enc = self.dropout3(enc)\n",
    "\n",
    "        enc = self.lstm4(enc)\n",
    "        enc = self.bn4(enc)\n",
    "        enc = self.dropout4(enc)\n",
    "\n",
    "        out1 = self.dense1_1(enc)\n",
    "        out1 = self.dense2_1(out1)\n",
    "\n",
    "        out2 = self.dense1_2(enc)\n",
    "        out2 = self.dense2_2(out2)\n",
    "\n",
    "        out = self.concat([out1, out2])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to build the next day vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "def makeNextDayVector(filtered_df, todays_date, stock, comp_name):\n",
    "    \n",
    "    \n",
    "    filtered_df['diff']=filtered_df['high']-filtered_df['low']\n",
    "    filtered_df['exp']=(filtered_df['open']+filtered_df['close'])/2\n",
    "    \n",
    "    \n",
    "    loaded_model = load_model('model.keras')\n",
    "    \n",
    "    curr_row = filtered_df[filtered_df['Date'] == todays_date]\n",
    "    \n",
    "    curr_row.drop(['date', 'Date', 'Name'], axis=1, inplace=True)\n",
    "    filtered_df.drop(['date', 'Date', 'Name'], axis=1, inplace=True)\n",
    "    \n",
    "    curr_stock_value = curr_row['open'].iloc[0]\n",
    "    \n",
    "    # find scaler\n",
    "    scaler = MinMaxScaler()\n",
    "    for dict in scalers_stock:\n",
    "        if dict['comp'] == comp_name:\n",
    "            scaler = dict['scaler']\n",
    "            break\n",
    "    \n",
    "    # normalise the df\n",
    "    filtered_df[filtered_df.columns] = scaler.transform(filtered_df[filtered_df.columns])\n",
    "\n",
    "    predicted_values = pd.DataFrame()\n",
    "    \n",
    "    predicted_values[['open', 'high', 'low', 'volume', 'close', 'Positve', 'Negative','Neutral', 'Total', 'NeutralPos', 'NeutralNeg']] = 0\n",
    "    \n",
    "    # predict the stock price\n",
    "    predicted_values[['diff', 'exp']] = loaded_model.predict(np.array([filtered_df.values]).astype(float))\n",
    "    \n",
    "    predicted_values[predicted_values.columns] = scaler.inverse_transform(predicted_values)\n",
    "    \n",
    "    \n",
    "    \n",
    "    predicted_values.drop(['open', 'high', 'low', 'volume', 'close', 'Positve', 'Negative','Neutral', 'Total', 'NeutralPos', 'NeutralNeg'], axis=1, inplace=True)\n",
    "    \n",
    "    \n",
    "    expected_value = predicted_values['exp'].iloc[0]\n",
    "    error = abs(predicted_values['diff']).iloc[0]\n",
    "    \n",
    "    percen_portfolio = stock['Percentage of portfolio']\n",
    "    percen_sector = stock['Percentage of sector']\n",
    "    sector = stock['Sector of Stock']\n",
    "    \n",
    "    positives = curr_row['Positve'].iloc[0]\n",
    "    negatives = curr_row['Negative'].iloc[0]\n",
    "    total = curr_row['Total'].iloc[0]\n",
    "    neutral = curr_row['Neutral'].iloc[0]\n",
    "    neutral_pos = curr_row['NeutralPos'].iloc[0]\n",
    "    neutral_neg = curr_row['NeutralNeg'].iloc[0]\n",
    "    \n",
    "    \n",
    "    # create the next day vector\n",
    "    stock_vect = []\n",
    "    stock_vect.append(curr_stock_value)\n",
    "    stock_vect.append(expected_value)\n",
    "    stock_vect.append(error)\n",
    "    stock_vect.append(percen_portfolio)\n",
    "    stock_vect.append(percen_sector)\n",
    "    stock_vect.append(positives)\n",
    "    stock_vect.append(negatives)\n",
    "    stock_vect.append(total)\n",
    "    stock_vect.append(neutral)\n",
    "    stock_vect.append(neutral_pos)\n",
    "    stock_vect.append(neutral_neg)\n",
    "    \n",
    "    return stock_vect\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making the next day vectors for the inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 609ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 628ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 562ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 545ms/step\n"
     ]
    }
   ],
   "source": [
    "next_vectors = []\n",
    "for i in range(len(list_of_stocks)):\n",
    "    if(list_of_stocks[i]['comp'] == 'AMZN'):\n",
    "        df = pd.read_csv('./Combining Stock and Twitter Data/MyDrive/AmazonStock_Sentiment_6M.csv');\n",
    "        filtered_df = df[df['Date'].replace('/', '') <= todays_date.replace('/', '')].tail(30)\n",
    "        next_vectors.append({'next_day_vector': makeNextDayVector(filtered_df, todays_date, list_of_stocks[i], 'AMZN'), 'comp': 'AMZN'})\n",
    "    elif(list_of_stocks[i]['comp'] == 'AAPL'):\n",
    "        df = pd.read_csv('./Combining Stock and Twitter Data/MyDrive/AAPLStock_sentiment_6M.csv')\n",
    "        filtered_df = df[df['Date'].replace('/', '') <= todays_date.replace('/', '')].tail(30)\n",
    "        next_vectors.append({'next_day_vector': makeNextDayVector(filtered_df, todays_date, list_of_stocks[i], 'AAPL'), 'comp': 'AAPL'})\n",
    "    elif(list_of_stocks[i]['comp'] == 'MSFT'):\n",
    "        df = pd.read_csv('./Combining Stock and Twitter Data/MyDrive/MSFTStock_Sentiment_6M.csv')\n",
    "        filtered_df = df[df['Date'].replace('/', '') <= todays_date.replace('/', '')].tail(30)\n",
    "        next_vectors.append({'next_day_vector': makeNextDayVector(filtered_df, todays_date, list_of_stocks[i], 'MSFT'), 'comp': 'MSFT'})\n",
    "    elif(list_of_stocks[i]['comp'] == 'PFIZER'):\n",
    "        df = pd.read_csv('./Combining Stock and Twitter Data/MyDrive/PfizerStock_Sentiment_6M.csv')\n",
    "        filtered_df = df[df['Date'].replace('/', '') <= todays_date.replace('/', '')].tail(30)\n",
    "        next_vectors.append({'next_day_vector': makeNextDayVector(filtered_df, todays_date, list_of_stocks[i], 'PFIZER'), 'comp': 'PFIZER'})\n",
    "    elif(list_of_stocks[i]['comp'] == 'CSCO'):\n",
    "        df = pd.read_csv('./Combining Stock and Twitter Data/MyDrive/CSCOStock_Sentiment_6M.csv')\n",
    "        filtered_df = df[df['Date'].replace('/', '') <= todays_date.replace('/', '')].tail(30)\n",
    "        next_vectors.append({'next_day_vector': makeNextDayVector(filtered_df, todays_date, list_of_stocks[i], 'CSCO'), 'comp': 'CSCO'})\n",
    "    elif(list_of_stocks[i]['comp'] == 'IBM'):\n",
    "        df = pd.read_csv('./Combining Stock and Twitter Data/MyDrive/IBMStock_Sentiment_6M.csv')\n",
    "        filtered_df = df[df['Date'].replace('/', '') <= todays_date.replace('/', '')].tail(30)\n",
    "        next_vectors.append({'next_day_vector': makeNextDayVector(filtered_df, todays_date, list_of_stocks[i], 'IBM'), 'comp': 'IBM'})\n",
    "    elif(list_of_stocks[i]['comp'] == 'JNJ'):\n",
    "        df = pd.read_csv('./Combining Stock and Twitter Data/MyDrive/JNJStock_Sentiment_6M.csv')\n",
    "        filtered_df = df[df['Date'].replace('/', '') <= todays_date.replace('/', '')].tail(30)\n",
    "        next_vectors.append({'next_day_vector': makeNextDayVector(filtered_df, todays_date, list_of_stocks[i], 'JNJ'), 'comp': 'JNJ'})\n",
    "    elif(list_of_stocks[i]['comp'] == 'JNPR'):\n",
    "        df = pd.read_csv('./Combining Stock and Twitter Data/MyDrive/JNPRStock_Sentiment_6M.csv')\n",
    "        filtered_df = df[df['Date'].replace('/', '') <= todays_date.replace('/', '')].tail(30)\n",
    "        next_vectors.append({'next_day_vector': makeNextDayVector(filtered_df, todays_date, list_of_stocks[i], 'JNPR'), 'comp': 'JNPR'})    \n",
    "    elif(list_of_stocks[i]['comp'] == 'ORCL'):\n",
    "        df = pd.read_csv('./Combining Stock and Twitter Data/MyDrive/ORCLStock_Sentiment_6M.csv')\n",
    "        filtered_df = df[df['Date'].replace('/', '') <= todays_date.replace('/', '')].tail(30)\n",
    "        next_vectors.append({'next_day_vector': makeNextDayVector(filtered_df, todays_date, list_of_stocks[i], 'ORCL'), 'comp': 'ORCL'})\n",
    "    elif(list_of_stocks[i]['comp'] == 'TGT'):\n",
    "        df = pd.read_csv('./Combining Stock and Twitter Data/MyDrive/TGTStock_Sentiment_6M.csv')\n",
    "        filtered_df = df[df['Date'].replace('/', '') <= todays_date.replace('/', '')].tail(30)\n",
    "        next_vectors.append({'next_day_vector': makeNextDayVector(filtered_df, todays_date, list_of_stocks[i], 'TGT'), 'comp': 'TGT'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1217.51,\n",
       " 1440.2086984586717,\n",
       " 54.31271990358817,\n",
       " 0.5,\n",
       " 15.56,\n",
       " 52.54403131,\n",
       " 6.653620352,\n",
       " 1022,\n",
       " 40.80234834,\n",
       " 52.54403131,\n",
       " 27.86822061]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_vectors[0]['next_day_vector']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre Processing stock decision df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Current Value of Stock</th>\n",
       "      <th>Expected Value of Stock</th>\n",
       "      <th>Error in expected value of stock</th>\n",
       "      <th>Percentage of portfolio</th>\n",
       "      <th>Percentage of sector</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Total</th>\n",
       "      <th>Neutral_Pos</th>\n",
       "      <th>Neutral_Neg</th>\n",
       "      <th>Buy/Sell/Keep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.016909</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.057341</td>\n",
       "      <td>0.747695</td>\n",
       "      <td>0.353394</td>\n",
       "      <td>0.634112</td>\n",
       "      <td>0.393651</td>\n",
       "      <td>0.209993</td>\n",
       "      <td>0.363674</td>\n",
       "      <td>0.354623</td>\n",
       "      <td>0.288915</td>\n",
       "      <td>Keep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.006546</td>\n",
       "      <td>0.003842</td>\n",
       "      <td>0.060510</td>\n",
       "      <td>0.875622</td>\n",
       "      <td>0.132926</td>\n",
       "      <td>0.659470</td>\n",
       "      <td>0.618285</td>\n",
       "      <td>0.282692</td>\n",
       "      <td>0.270249</td>\n",
       "      <td>0.399351</td>\n",
       "      <td>0.499607</td>\n",
       "      <td>Keep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030124</td>\n",
       "      <td>0.046401</td>\n",
       "      <td>0.038742</td>\n",
       "      <td>0.334798</td>\n",
       "      <td>0.612328</td>\n",
       "      <td>0.595365</td>\n",
       "      <td>0.277965</td>\n",
       "      <td>0.318172</td>\n",
       "      <td>0.316199</td>\n",
       "      <td>0.429087</td>\n",
       "      <td>Buy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.027272</td>\n",
       "      <td>0.042233</td>\n",
       "      <td>0.108571</td>\n",
       "      <td>0.334854</td>\n",
       "      <td>0.926111</td>\n",
       "      <td>0.890981</td>\n",
       "      <td>0.371262</td>\n",
       "      <td>0.382849</td>\n",
       "      <td>0.149471</td>\n",
       "      <td>0.807705</td>\n",
       "      <td>0.553326</td>\n",
       "      <td>Sell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.037013</td>\n",
       "      <td>0.058251</td>\n",
       "      <td>0.039837</td>\n",
       "      <td>0.165370</td>\n",
       "      <td>0.620705</td>\n",
       "      <td>0.575857</td>\n",
       "      <td>0.650335</td>\n",
       "      <td>0.326131</td>\n",
       "      <td>0.332083</td>\n",
       "      <td>0.251870</td>\n",
       "      <td>0.433689</td>\n",
       "      <td>Buy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Current Value of Stock  Expected Value of Stock  \\\n",
       "0                0.016909                 0.000000   \n",
       "1                0.006546                 0.003842   \n",
       "2                0.000000                 0.030124   \n",
       "3                0.027272                 0.042233   \n",
       "4                0.037013                 0.058251   \n",
       "\n",
       "   Error in expected value of stock  Percentage of portfolio  \\\n",
       "0                          0.057341                 0.747695   \n",
       "1                          0.060510                 0.875622   \n",
       "2                          0.046401                 0.038742   \n",
       "3                          0.108571                 0.334854   \n",
       "4                          0.039837                 0.165370   \n",
       "\n",
       "   Percentage of sector  Positive  Negative   Neutral     Total  Neutral_Pos  \\\n",
       "0              0.353394  0.634112  0.393651  0.209993  0.363674     0.354623   \n",
       "1              0.132926  0.659470  0.618285  0.282692  0.270249     0.399351   \n",
       "2              0.334798  0.612328  0.595365  0.277965  0.318172     0.316199   \n",
       "3              0.926111  0.890981  0.371262  0.382849  0.149471     0.807705   \n",
       "4              0.620705  0.575857  0.650335  0.326131  0.332083     0.251870   \n",
       "\n",
       "   Neutral_Neg Buy/Sell/Keep  \n",
       "0     0.288915          Keep  \n",
       "1     0.499607          Keep  \n",
       "2     0.429087           Buy  \n",
       "3     0.553326          Sell  \n",
       "4     0.433689           Buy  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_decisions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Breaking down into buy, sell and keep dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "buy_df = df_decisions[df_decisions['Buy/Sell/Keep'] == 'Buy']\n",
    "\n",
    "sell_df = df_decisions[df_decisions['Buy/Sell/Keep'] == 'Sell']\n",
    "\n",
    "keep_df = df_decisions[df_decisions['Buy/Sell/Keep'] == 'Keep']\n",
    "\n",
    "buy_df.drop(columns=['Buy/Sell/Keep'], inplace=True)\n",
    "sell_df.drop(columns=['Buy/Sell/Keep'], inplace=True)\n",
    "keep_df.drop(columns=['Buy/Sell/Keep'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Current Value of Stock</th>\n",
       "      <th>Expected Value of Stock</th>\n",
       "      <th>Error in expected value of stock</th>\n",
       "      <th>Percentage of portfolio</th>\n",
       "      <th>Percentage of sector</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Total</th>\n",
       "      <th>Neutral_Pos</th>\n",
       "      <th>Neutral_Neg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.016909</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.057341</td>\n",
       "      <td>0.747695</td>\n",
       "      <td>0.353394</td>\n",
       "      <td>0.634112</td>\n",
       "      <td>0.393651</td>\n",
       "      <td>0.209993</td>\n",
       "      <td>0.363674</td>\n",
       "      <td>0.354623</td>\n",
       "      <td>0.288915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.006546</td>\n",
       "      <td>0.003842</td>\n",
       "      <td>0.060510</td>\n",
       "      <td>0.875622</td>\n",
       "      <td>0.132926</td>\n",
       "      <td>0.659470</td>\n",
       "      <td>0.618285</td>\n",
       "      <td>0.282692</td>\n",
       "      <td>0.270249</td>\n",
       "      <td>0.399351</td>\n",
       "      <td>0.499607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.067410</td>\n",
       "      <td>0.057948</td>\n",
       "      <td>0.091527</td>\n",
       "      <td>0.163465</td>\n",
       "      <td>0.959393</td>\n",
       "      <td>0.496957</td>\n",
       "      <td>0.459654</td>\n",
       "      <td>0.264011</td>\n",
       "      <td>0.460825</td>\n",
       "      <td>0.112700</td>\n",
       "      <td>0.191714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.073335</td>\n",
       "      <td>0.059970</td>\n",
       "      <td>0.023276</td>\n",
       "      <td>0.379841</td>\n",
       "      <td>0.060957</td>\n",
       "      <td>0.552564</td>\n",
       "      <td>0.356246</td>\n",
       "      <td>0.273914</td>\n",
       "      <td>0.445859</td>\n",
       "      <td>0.210784</td>\n",
       "      <td>0.168752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.064008</td>\n",
       "      <td>0.069635</td>\n",
       "      <td>0.077863</td>\n",
       "      <td>0.330739</td>\n",
       "      <td>0.747575</td>\n",
       "      <td>0.608680</td>\n",
       "      <td>0.618348</td>\n",
       "      <td>0.294846</td>\n",
       "      <td>0.313993</td>\n",
       "      <td>0.309765</td>\n",
       "      <td>0.443775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1059</th>\n",
       "      <td>0.777316</td>\n",
       "      <td>0.826290</td>\n",
       "      <td>0.457143</td>\n",
       "      <td>0.564369</td>\n",
       "      <td>0.700073</td>\n",
       "      <td>0.576933</td>\n",
       "      <td>0.578050</td>\n",
       "      <td>0.158835</td>\n",
       "      <td>0.380911</td>\n",
       "      <td>0.420627</td>\n",
       "      <td>0.404228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1062</th>\n",
       "      <td>0.903199</td>\n",
       "      <td>0.928010</td>\n",
       "      <td>0.604396</td>\n",
       "      <td>0.570575</td>\n",
       "      <td>0.228781</td>\n",
       "      <td>0.670365</td>\n",
       "      <td>0.294132</td>\n",
       "      <td>0.184211</td>\n",
       "      <td>0.440210</td>\n",
       "      <td>0.548578</td>\n",
       "      <td>0.204860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1064</th>\n",
       "      <td>0.895305</td>\n",
       "      <td>0.850074</td>\n",
       "      <td>0.470330</td>\n",
       "      <td>0.173859</td>\n",
       "      <td>0.665147</td>\n",
       "      <td>0.383629</td>\n",
       "      <td>0.419840</td>\n",
       "      <td>0.137218</td>\n",
       "      <td>0.614365</td>\n",
       "      <td>0.347657</td>\n",
       "      <td>0.205120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1067</th>\n",
       "      <td>0.841712</td>\n",
       "      <td>0.773625</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.456054</td>\n",
       "      <td>0.807529</td>\n",
       "      <td>0.416400</td>\n",
       "      <td>0.683732</td>\n",
       "      <td>0.274436</td>\n",
       "      <td>0.461552</td>\n",
       "      <td>0.200784</td>\n",
       "      <td>0.373375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1069</th>\n",
       "      <td>0.687578</td>\n",
       "      <td>0.670418</td>\n",
       "      <td>0.443956</td>\n",
       "      <td>0.043862</td>\n",
       "      <td>0.383637</td>\n",
       "      <td>0.378117</td>\n",
       "      <td>0.690154</td>\n",
       "      <td>0.341165</td>\n",
       "      <td>0.489754</td>\n",
       "      <td>0.148356</td>\n",
       "      <td>0.347666</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>448 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Current Value of Stock  Expected Value of Stock  \\\n",
       "0                   0.016909                 0.000000   \n",
       "1                   0.006546                 0.003842   \n",
       "5                   0.067410                 0.057948   \n",
       "6                   0.073335                 0.059970   \n",
       "7                   0.064008                 0.069635   \n",
       "...                      ...                      ...   \n",
       "1059                0.777316                 0.826290   \n",
       "1062                0.903199                 0.928010   \n",
       "1064                0.895305                 0.850074   \n",
       "1067                0.841712                 0.773625   \n",
       "1069                0.687578                 0.670418   \n",
       "\n",
       "      Error in expected value of stock  Percentage of portfolio  \\\n",
       "0                             0.057341                 0.747695   \n",
       "1                             0.060510                 0.875622   \n",
       "5                             0.091527                 0.163465   \n",
       "6                             0.023276                 0.379841   \n",
       "7                             0.077863                 0.330739   \n",
       "...                                ...                      ...   \n",
       "1059                          0.457143                 0.564369   \n",
       "1062                          0.604396                 0.570575   \n",
       "1064                          0.470330                 0.173859   \n",
       "1067                          0.942857                 0.456054   \n",
       "1069                          0.443956                 0.043862   \n",
       "\n",
       "      Percentage of sector  Positive  Negative   Neutral     Total  \\\n",
       "0                 0.353394  0.634112  0.393651  0.209993  0.363674   \n",
       "1                 0.132926  0.659470  0.618285  0.282692  0.270249   \n",
       "5                 0.959393  0.496957  0.459654  0.264011  0.460825   \n",
       "6                 0.060957  0.552564  0.356246  0.273914  0.445859   \n",
       "7                 0.747575  0.608680  0.618348  0.294846  0.313993   \n",
       "...                    ...       ...       ...       ...       ...   \n",
       "1059              0.700073  0.576933  0.578050  0.158835  0.380911   \n",
       "1062              0.228781  0.670365  0.294132  0.184211  0.440210   \n",
       "1064              0.665147  0.383629  0.419840  0.137218  0.614365   \n",
       "1067              0.807529  0.416400  0.683732  0.274436  0.461552   \n",
       "1069              0.383637  0.378117  0.690154  0.341165  0.489754   \n",
       "\n",
       "      Neutral_Pos  Neutral_Neg  \n",
       "0        0.354623     0.288915  \n",
       "1        0.399351     0.499607  \n",
       "5        0.112700     0.191714  \n",
       "6        0.210784     0.168752  \n",
       "7        0.309765     0.443775  \n",
       "...           ...          ...  \n",
       "1059     0.420627     0.404228  \n",
       "1062     0.548578     0.204860  \n",
       "1064     0.347657     0.205120  \n",
       "1067     0.200784     0.373375  \n",
       "1069     0.148356     0.347666  \n",
       "\n",
       "[448 rows x 11 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keep_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'next_day_vector': [1217.51,\n",
       "   1440.2086984586717,\n",
       "   54.31271990358817,\n",
       "   0.5,\n",
       "   15.56,\n",
       "   52.54403131,\n",
       "   6.653620352,\n",
       "   1022,\n",
       "   40.80234834,\n",
       "   52.54403131,\n",
       "   27.86822061],\n",
       "  'comp': 'AMZN'},\n",
       " {'next_day_vector': [87.66,\n",
       "   92.82440862655642,\n",
       "   1.8587952208518992,\n",
       "   4.5,\n",
       "   7.8,\n",
       "   39.01581722,\n",
       "   11.42355009,\n",
       "   569,\n",
       "   49.56063269,\n",
       "   41.36386314,\n",
       "   11.42355009],\n",
       "  'comp': 'MSFT'},\n",
       " {'next_day_vector': [173.44,\n",
       "   167.11862921042442,\n",
       "   2.707145949840536,\n",
       "   7.5,\n",
       "   18.26,\n",
       "   48.41208366,\n",
       "   9.295120062,\n",
       "   1291,\n",
       "   42.29279628,\n",
       "   48.41208366,\n",
       "   17.84049339],\n",
       "  'comp': 'AAPL'},\n",
       " {'next_day_vector': [36.82,\n",
       "   36.48794911816716,\n",
       "   0.7796059048175816,\n",
       "   16.5,\n",
       "   10.26,\n",
       "   36.4640884,\n",
       "   3.867403315,\n",
       "   181,\n",
       "   59.66850829,\n",
       "   36.4640884,\n",
       "   9.16082135],\n",
       "  'comp': 'PFIZER'}]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalising the next vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in next_vectors:\n",
    "    scaler = MinMaxScaler()\n",
    "    for dict in scalers_decisions:\n",
    "        if dict['comp'] == i['comp']:\n",
    "            scaler = dict['scaler']\n",
    "            break\n",
    "    \n",
    "    normalized_array = scaler.transform([i['next_day_vector']])\n",
    "    normalized_list = normalized_array.flatten()\n",
    "    i['next_day_vector'] = normalized_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'next_day_vector': array([ 0.45475742,  0.81340574,  0.36662683, -0.01902568,  0.70143324,\n",
       "          1.        ,  0.33451766,  0.21426964,  0.0672408 ,  1.        ,\n",
       "          0.64337853]),\n",
       "  'comp': 'AMZN'},\n",
       " {'next_day_vector': array([0.62833487, 0.89597133, 0.25807905, 0.93068418, 0.16783359,\n",
       "         0.32479996, 0.30247938, 0.11842981, 0.61712824, 0.43254837,\n",
       "         0.21429368]),\n",
       "  'comp': 'MSFT'},\n",
       " {'next_day_vector': array([0.76961927, 0.52680659, 0.20900822, 1.56984983, 0.88343687,\n",
       "         0.78368612, 0.23917044, 0.30149413, 0.26098711, 0.65903313,\n",
       "         0.44507208]),\n",
       "  'comp': 'AAPL'},\n",
       " {'next_day_vector': array([0.54958678, 0.47837624, 0.23793885, 3.65981051, 0.34478131,\n",
       "         0.83804257, 0.21897318, 0.16624685, 0.30819748, 0.75803476,\n",
       "         0.33570377]),\n",
       "  'comp': 'PFIZER'}]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying cosine similarity between Next day stock vector and user decision vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# similarty \n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "buy_score = []\n",
    "sell_score = []\n",
    "keep_score = []\n",
    "\n",
    "for i in range(len(next_vectors)):\n",
    "    buy_score_similarity = 0\n",
    "    buy_score_similarity = cosine_similarity(buy_df.values, [next_vectors[i]['next_day_vector']])\n",
    "    total_cos_buy_score = np.average(buy_score_similarity)\n",
    "    buy_score.append({'buyscore': total_cos_buy_score, 'comp': next_vectors[i]['comp']})\n",
    "    \n",
    "    \n",
    "    sell_score_similarity = 0\n",
    "    sell_score_similarity = cosine_similarity(sell_df.values, [next_vectors[i]['next_day_vector']])\n",
    "    \n",
    "    total_cos_sell_score = np.average(sell_score_similarity)\n",
    "    sell_score.append({'sellscore': total_cos_sell_score, 'comp': next_vectors[i]['comp']})\n",
    "    \n",
    "    keep_score_similarity = 0\n",
    "    keep_score_similarity = cosine_similarity(keep_df.values, [next_vectors[i]['next_day_vector']])\n",
    "    total_cos_keep_score = np.average(keep_score_similarity)\n",
    "    keep_score.append({'keepscore': total_cos_keep_score, 'comp': next_vectors[i]['comp']})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing buy, sell and keep scores of each company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'AMZN': {'buy': 0.7281041427036561, 'sell': 0.7144008918293004, 'keep': 0.702791886932548}, 'MSFT': {'buy': 0.8083289970965074, 'sell': 0.8071396442731366, 'keep': 0.8072339977922515}, 'AAPL': {'buy': 0.7951848092609144, 'sell': 0.7967859540532392, 'keep': 0.7969255168678114}, 'PFIZER': {'buy': 0.5899800920254605, 'sell': 0.5948927891429138, 'keep': 0.6011937564883656}}\n"
     ]
    }
   ],
   "source": [
    "company_scores = {}\n",
    "\n",
    "# Merge the scores for each company\n",
    "for score_list, score_type in zip([buy_score, sell_score, keep_score], ['buy', 'sell', 'keep']):\n",
    "    for score in score_list:\n",
    "        comp = score['comp']\n",
    "        score_value = score[score_type + 'score']\n",
    "        if comp not in company_scores:\n",
    "            company_scores[comp] = {'buy': None, 'sell': None, 'keep': None}\n",
    "        company_scores[comp][score_type] = score_value\n",
    "\n",
    "print(company_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommending which stocks to buy, sell and keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buy Stocks: ['AMZN', 'MSFT']\n",
      "Sell Stocks: []\n",
      "Keep Stocks: ['AAPL', 'PFIZER']\n"
     ]
    }
   ],
   "source": [
    "buy_basket = []\n",
    "sell_basket = []\n",
    "keep_basket = []\n",
    "\n",
    "for company, scores in company_scores.items():\n",
    "    buy_score = scores['buy']\n",
    "    sell_score = scores['sell']\n",
    "    keep_score = scores['keep']\n",
    "    \n",
    "    if buy_score is not None and (sell_score is None or buy_score > sell_score) and (keep_score is None or buy_score > keep_score):\n",
    "        buy_basket.append(company)\n",
    "    elif sell_score is not None and (buy_score is None or sell_score > buy_score) and (keep_score is None or sell_score > keep_score):\n",
    "        sell_basket.append(company)\n",
    "    elif keep_score is not None and (buy_score is None or keep_score > buy_score) and (sell_score is None or keep_score > sell_score):\n",
    "        keep_basket.append(company)\n",
    "\n",
    "print(\"Buy Stocks:\", buy_basket)\n",
    "print(\"Sell Stocks:\", sell_basket)\n",
    "print(\"Keep Stocks:\", keep_basket)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recsys",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
