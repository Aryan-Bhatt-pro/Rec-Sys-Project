{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1664,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "from keras import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1665,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_decisions_list = []\n",
    "df_decisions_list.append({'df': pd.read_csv('./amazon_stock_trades.csv'), 'comp': 'AMZN'})\n",
    "df_decisions_list.append({'df': pd.read_csv('./apple_stock_trades.csv'), 'comp': 'AAPL'})\n",
    "df_decisions_list.append({'df': pd.read_csv('./cisco_stock_trades.csv'), 'comp': 'CSCO'})\n",
    "df_decisions_list.append({'df': pd.read_csv('./ibm_stock_trades.csv'), 'comp': 'IBM'})\n",
    "df_decisions_list.append({'df': pd.read_csv('./jnj_stock_trades.csv'), 'comp': 'JNJ'})\n",
    "df_decisions_list.append({'df': pd.read_csv('./jnpr_stock_trades.csv'), 'comp': 'JNPR'})\n",
    "df_decisions_list.append({'df': pd.read_csv('./msft_stock_trades.csv'), 'comp': 'MSFT'})\n",
    "df_decisions_list.append({'df': pd.read_csv('./orcl_stock_trades.csv'), 'comp': 'ORCL'})\n",
    "df_decisions_list.append({'df': pd.read_csv('./pfizer_stock_trades.csv'), 'comp': 'PFIZER'})\n",
    "df_decisions_list.append({'df': pd.read_csv('./tgt_stock_trades.csv'), 'comp': 'TGT'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1666,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "columns_to_exclude = ['Sector of stock', 'Buy/Sell/Keep']\n",
    "columns_to_normalize = ['Current Value of Stock', 'Expected Value of Stock', 'Error in expected value of stock', 'Percentage of portfolio', 'Percentage of sector', 'Positive', 'Negative', 'Neutral', 'Total', 'Neutral_Pos', 'Neutral_Neg']\n",
    "scalers_decisions = []\n",
    "for i in range(len(df_decisions_list)):\n",
    "    scaler = MinMaxScaler()\n",
    "    normalized_values = scaler.fit_transform(df_decisions_list[i]['df'][columns_to_normalize])\n",
    "    normalized_df = pd.DataFrame(normalized_values, columns=columns_to_normalize)\n",
    "    scalers_decisions.append({'scaler': scaler, 'comp': df_decisions_list[i]['comp']})\n",
    "\n",
    "    # Concatenate the normalized DataFrame with the excluded column\n",
    "    df_decisions_list[i]['df'] = pd.concat([normalized_df, df_decisions_list[i]['df'][columns_to_exclude]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1667,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'scaler': MinMaxScaler(), 'comp': 'AMZN'},\n",
       " {'scaler': MinMaxScaler(), 'comp': 'AAPL'},\n",
       " {'scaler': MinMaxScaler(), 'comp': 'CSCO'},\n",
       " {'scaler': MinMaxScaler(), 'comp': 'IBM'},\n",
       " {'scaler': MinMaxScaler(), 'comp': 'JNJ'},\n",
       " {'scaler': MinMaxScaler(), 'comp': 'JNPR'},\n",
       " {'scaler': MinMaxScaler(), 'comp': 'MSFT'},\n",
       " {'scaler': MinMaxScaler(), 'comp': 'ORCL'},\n",
       " {'scaler': MinMaxScaler(), 'comp': 'PFIZER'},\n",
       " {'scaler': MinMaxScaler(), 'comp': 'TGT'}]"
      ]
     },
     "execution_count": 1667,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalers_decisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1668,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df = []\n",
    "main_df.append({'df': pd.read_csv('./Combining Stock and Twitter Data/MyDrive/AmazonStock_Sentiment_6M.csv').drop(['date','Date','Name'],axis=1), 'comp': 'AMZN'})\n",
    "main_df.append({'df': pd.read_csv('./Combining Stock and Twitter Data/MyDrive/AAPLStock_sentiment_6M.csv').drop(['date','Date','Name'],axis=1), 'comp': 'AAPL'})\n",
    "main_df.append({'df': pd.read_csv('./Combining Stock and Twitter Data/MyDrive/CSCOStock_Sentiment_6M.csv').drop(['date','Date','Name'],axis=1), 'comp': 'CSCO'})\n",
    "main_df.append({'df': pd.read_csv('./Combining Stock and Twitter Data/MyDrive/IBMStock_Sentiment_6M.csv').drop(['date','Date','Name'],axis=1), 'comp': 'IBM'})\n",
    "main_df.append({'df': pd.read_csv('./Combining Stock and Twitter Data/MyDrive/JNJStock_Sentiment_6M.csv').drop(['date','Date','Name'],axis=1), 'comp': 'JNJ'})\n",
    "main_df.append({'df': pd.read_csv('./Combining Stock and Twitter Data/MyDrive/JNPRStock_Sentiment_6M.csv').drop(['date','Date','Name'],axis=1), 'comp': 'JNPR'})\n",
    "main_df.append({'df': pd.read_csv('./Combining Stock and Twitter Data/MyDrive/MSFTStock_Sentiment_6M.csv').drop(['date','Date','Name'],axis=1), 'comp': 'MSFT'})\n",
    "main_df.append({'df': pd.read_csv('./Combining Stock and Twitter Data/MyDrive/ORCLStock_Sentiment_6M.csv').drop(['date','Date','Name'],axis=1), 'comp': 'ORCL'})\n",
    "main_df.append({'df': pd.read_csv('./Combining Stock and Twitter Data/MyDrive/PfizerStock_Sentiment_6M.csv').drop(['date','Date','Name'],axis=1), 'comp': 'PFIZER'})\n",
    "main_df.append({'df': pd.read_csv('./Combining Stock and Twitter Data/MyDrive/TGTStock_Sentiment_6M.csv').drop(['date','Date','Name'],axis=1), 'comp': 'TGT'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1669,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalers_stock = []\n",
    "for i in range(len(main_df)):\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    main_df[i]['df'][main_df[i]['df'].columns] = scaler.fit_transform(main_df[i]['df'][main_df[i]['df'].columns])\n",
    "    scalers_stock.append({'scaler': scaler, 'comp': main_df[i]['comp']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1670,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the diff and exp column\n",
    "for i in main_df:\n",
    "    i['df']['diff']=i['df']['high']-i['df']['low']\n",
    "for i in main_df:\n",
    "    i['df']['exp']=(i['df']['open']+i['df']['close'])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1671,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.01690875490077537 0.0 0.0573411800211275 ... 0.2889154068034872 'IT'\n",
      "  'Keep']\n",
      " [0.006545881621444094 0.003842394418416717 0.06051003470650517 ...\n",
      "  0.4996072102743184 'IT' 'Keep']\n",
      " [0.0 0.030124035188243692 0.04640108646446504 ... 0.42908697933553197\n",
      "  'IT' 'Buy']\n",
      " ...\n",
      " [0.8417116742833404 0.7736249734550866 0.9428571428571434 ...\n",
      "  0.37337504235759883 'Consumer Discretionary' 'Keep']\n",
      " [0.8201080182800169 0.6982374177107671 0.2527472527472538 ...\n",
      "  0.5026178016456893 'Consumer Discretionary' 'Sell']\n",
      " [0.6875778977980893 0.6704183478445533 0.44395604395604266 ...\n",
      "  0.3476663784289607 'Consumer Discretionary' 'Keep']]\n"
     ]
    }
   ],
   "source": [
    "dataset = []\n",
    "for i in df_decisions_list:\n",
    "    dataset.append(i['df'].values)\n",
    "dataset = np.concatenate(dataset, axis = 0)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1672,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_decisions = pd.DataFrame(dataset, columns=['Current Value of Stock', 'Expected Value of Stock', 'Error in expected value of stock', 'Percentage of portfolio', 'Percentage of sector', 'Positive', 'Negative', 'Neutral', 'Total', 'Neutral_Pos', 'Neutral_Neg', 'Sector of stock','Buy/Sell/Keep'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1673,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_decisions.drop('Sector of stock', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1674,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_encoded = pd.get_dummies(df_decisions['Buy/Sell/Keep'], prefix='Buy/Sell/Keep')\n",
    "one_hot_encoded = one_hot_encoded.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1675,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_decision_one_hot = df_decisions.drop(labels = 'Buy/Sell/Keep', axis=1)\n",
    "df_decision_one_hot = pd.concat([df_decision_one_hot, one_hot_encoded], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1676,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Current Value of Stock</th>\n",
       "      <th>Expected Value of Stock</th>\n",
       "      <th>Error in expected value of stock</th>\n",
       "      <th>Percentage of portfolio</th>\n",
       "      <th>Percentage of sector</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Total</th>\n",
       "      <th>Neutral_Pos</th>\n",
       "      <th>Neutral_Neg</th>\n",
       "      <th>Buy/Sell/Keep_Buy</th>\n",
       "      <th>Buy/Sell/Keep_Keep</th>\n",
       "      <th>Buy/Sell/Keep_Sell</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.016909</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.057341</td>\n",
       "      <td>0.747695</td>\n",
       "      <td>0.353394</td>\n",
       "      <td>0.634112</td>\n",
       "      <td>0.393651</td>\n",
       "      <td>0.209993</td>\n",
       "      <td>0.363674</td>\n",
       "      <td>0.354623</td>\n",
       "      <td>0.288915</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.006546</td>\n",
       "      <td>0.003842</td>\n",
       "      <td>0.06051</td>\n",
       "      <td>0.875622</td>\n",
       "      <td>0.132926</td>\n",
       "      <td>0.65947</td>\n",
       "      <td>0.618285</td>\n",
       "      <td>0.282692</td>\n",
       "      <td>0.270249</td>\n",
       "      <td>0.399351</td>\n",
       "      <td>0.499607</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.030124</td>\n",
       "      <td>0.046401</td>\n",
       "      <td>0.038742</td>\n",
       "      <td>0.334798</td>\n",
       "      <td>0.612328</td>\n",
       "      <td>0.595365</td>\n",
       "      <td>0.277965</td>\n",
       "      <td>0.318172</td>\n",
       "      <td>0.316199</td>\n",
       "      <td>0.429087</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.027272</td>\n",
       "      <td>0.042233</td>\n",
       "      <td>0.108571</td>\n",
       "      <td>0.334854</td>\n",
       "      <td>0.926111</td>\n",
       "      <td>0.890981</td>\n",
       "      <td>0.371262</td>\n",
       "      <td>0.382849</td>\n",
       "      <td>0.149471</td>\n",
       "      <td>0.807705</td>\n",
       "      <td>0.553326</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.037013</td>\n",
       "      <td>0.058251</td>\n",
       "      <td>0.039837</td>\n",
       "      <td>0.16537</td>\n",
       "      <td>0.620705</td>\n",
       "      <td>0.575857</td>\n",
       "      <td>0.650335</td>\n",
       "      <td>0.326131</td>\n",
       "      <td>0.332083</td>\n",
       "      <td>0.25187</td>\n",
       "      <td>0.433689</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Current Value of Stock Expected Value of Stock  \\\n",
       "0               0.016909                     0.0   \n",
       "1               0.006546                0.003842   \n",
       "2                    0.0                0.030124   \n",
       "3               0.027272                0.042233   \n",
       "4               0.037013                0.058251   \n",
       "\n",
       "  Error in expected value of stock Percentage of portfolio  \\\n",
       "0                         0.057341                0.747695   \n",
       "1                          0.06051                0.875622   \n",
       "2                         0.046401                0.038742   \n",
       "3                         0.108571                0.334854   \n",
       "4                         0.039837                 0.16537   \n",
       "\n",
       "  Percentage of sector  Positive  Negative   Neutral     Total Neutral_Pos  \\\n",
       "0             0.353394  0.634112  0.393651  0.209993  0.363674    0.354623   \n",
       "1             0.132926   0.65947  0.618285  0.282692  0.270249    0.399351   \n",
       "2             0.334798  0.612328  0.595365  0.277965  0.318172    0.316199   \n",
       "3             0.926111  0.890981  0.371262  0.382849  0.149471    0.807705   \n",
       "4             0.620705  0.575857  0.650335  0.326131  0.332083     0.25187   \n",
       "\n",
       "  Neutral_Neg  Buy/Sell/Keep_Buy  Buy/Sell/Keep_Keep  Buy/Sell/Keep_Sell  \n",
       "0    0.288915                  0                   1                   0  \n",
       "1    0.499607                  0                   1                   0  \n",
       "2    0.429087                  1                   0                   0  \n",
       "3    0.553326                  0                   0                   1  \n",
       "4    0.433689                  1                   0                   0  "
      ]
     },
     "execution_count": 1676,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_decision_one_hot.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing K means clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1677,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-63 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-63 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-63 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-63 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-63 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-63 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-63 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-63 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-63 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-63 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-63 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-63 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-63 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-63 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-63 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-63 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-63 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-63 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-63 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-63 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-63 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-63 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-63 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-63 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-63 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-63 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-63 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-63 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-63 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-63 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-63 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-63 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-63 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-63 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-63 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-63 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-63 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-63 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-63 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-63 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-63 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-63 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-63\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KMeans(n_clusters=10, random_state=108)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-63\" type=\"checkbox\" checked><label for=\"sk-estimator-id-63\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;KMeans<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.cluster.KMeans.html\">?<span>Documentation for KMeans</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>KMeans(n_clusters=10, random_state=108)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "KMeans(n_clusters=10, random_state=108)"
      ]
     },
     "execution_count": 1677,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 10\n",
    "kmeans = KMeans(n_clusters=k, random_state=108)\n",
    "kmeans.fit(df_decision_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1678,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids = kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1679,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.29804061e-01,  2.30671152e-01,  1.29854513e-01,\n",
       "         4.16998893e-01,  3.97678380e-01,  3.74816378e-01,\n",
       "         2.26839814e-01,  2.21909891e-01,  6.29109674e-01,\n",
       "         4.07545066e-01,  1.48913279e-01,  5.55111512e-17,\n",
       "         1.00000000e+00, -2.22044605e-16],\n",
       "       [ 6.89566315e-01,  7.71831113e-01,  1.64517789e-01,\n",
       "         5.01491424e-01,  4.86153538e-01,  4.53477058e-01,\n",
       "         3.10242948e-01,  2.61681912e-01,  5.24971314e-01,\n",
       "         3.82245179e-01,  2.30367282e-01,  1.00000000e+00,\n",
       "         2.22044605e-16, -1.66533454e-16],\n",
       "       [ 3.02200425e-01,  2.34692727e-01,  1.74494212e-01,\n",
       "         5.30750788e-01,  4.71397641e-01,  3.71918116e-01,\n",
       "         3.52789279e-01,  2.50261144e-01,  5.89408044e-01,\n",
       "         3.66790745e-01,  2.31884259e-01,  5.55111512e-17,\n",
       "        -1.11022302e-16,  1.00000000e+00],\n",
       "       [ 3.94986744e-01,  3.88362885e-01,  1.61655681e-01,\n",
       "         7.91093923e-01,  7.52094064e-01,  3.97351721e-01,\n",
       "         3.06486119e-01,  2.43440322e-01,  5.84874267e-01,\n",
       "         3.76070014e-01,  1.96290849e-01,  0.00000000e+00,\n",
       "         1.00000000e+00, -1.11022302e-16],\n",
       "       [ 7.85176594e-01,  7.20688503e-01,  2.60589064e-01,\n",
       "         4.86175318e-01,  6.17563492e-01,  4.17510869e-01,\n",
       "         3.30849633e-01,  2.85758398e-01,  5.42834881e-01,\n",
       "         3.90041639e-01,  2.48474202e-01,  5.55111512e-17,\n",
       "         1.66533454e-16,  1.00000000e+00],\n",
       "       [ 3.89583352e-01,  4.44053929e-01,  1.63668573e-01,\n",
       "         4.88647396e-01,  5.25263054e-01,  6.94254441e-01,\n",
       "         5.03801660e-01,  3.32372166e-01,  2.52625572e-01,\n",
       "         5.35908433e-01,  5.23126835e-01,  1.00000000e+00,\n",
       "         2.22044605e-16, -1.11022302e-16],\n",
       "       [ 6.04979287e-01,  5.37326837e-01,  1.55507770e-01,\n",
       "         5.42371463e-01,  2.50703632e-01,  7.26463721e-01,\n",
       "         3.70735573e-01,  3.00529072e-01,  2.96281468e-01,\n",
       "         6.12348585e-01,  4.25805570e-01,  5.55111512e-17,\n",
       "         1.11022302e-16,  1.00000000e+00],\n",
       "       [ 2.20313559e-01,  2.83838034e-01,  1.52353325e-01,\n",
       "         5.35507000e-01,  4.83538759e-01,  3.70846953e-01,\n",
       "         2.64871882e-01,  2.37716229e-01,  6.26393881e-01,\n",
       "         4.04386361e-01,  1.64948951e-01,  1.00000000e+00,\n",
       "         1.11022302e-16, -2.22044605e-16],\n",
       "       [ 7.53780808e-01,  7.55141374e-01,  2.45783040e-01,\n",
       "         5.19895909e-01,  4.47584048e-01,  4.79315471e-01,\n",
       "         2.89907778e-01,  2.46221387e-01,  5.30155122e-01,\n",
       "         4.45621712e-01,  2.21755618e-01,  1.11022302e-16,\n",
       "         1.00000000e+00, -2.22044605e-16],\n",
       "       [ 3.80270022e-01,  3.74180995e-01,  1.41191015e-01,\n",
       "         4.94285730e-01,  5.10385480e-01,  6.21291059e-01,\n",
       "         5.89508885e-01,  3.08904313e-01,  2.45842990e-01,\n",
       "         4.58440244e-01,  5.96555318e-01,  5.55111512e-17,\n",
       "         1.00000000e+00,  0.00000000e+00]])"
      ]
     },
     "execution_count": 1679,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centroids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting predictions for next day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1680,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1681,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df = []\n",
    "main_df.append({'df': pd.read_csv('./Combining Stock and Twitter Data/MyDrive/AmazonStock_Sentiment_6M.csv').drop(['date','Date','Name'],axis=1), 'comp': 'AMZN'})\n",
    "main_df.append({'df': pd.read_csv('./Combining Stock and Twitter Data/MyDrive/AAPLStock_sentiment_6M.csv').drop(['date','Date','Name'],axis=1), 'comp': 'AAPL'})\n",
    "main_df.append({'df': pd.read_csv('./Combining Stock and Twitter Data/MyDrive/CSCOStock_Sentiment_6M.csv').drop(['date','Date','Name'],axis=1), 'comp': 'CSCO'})\n",
    "main_df.append({'df': pd.read_csv('./Combining Stock and Twitter Data/MyDrive/IBMStock_Sentiment_6M.csv').drop(['date','Date','Name'],axis=1), 'comp': 'IBM'})\n",
    "main_df.append({'df': pd.read_csv('./Combining Stock and Twitter Data/MyDrive/JNJStock_Sentiment_6M.csv').drop(['date','Date','Name'],axis=1), 'comp': 'JNJ'})\n",
    "main_df.append({'df': pd.read_csv('./Combining Stock and Twitter Data/MyDrive/JNPRStock_Sentiment_6M.csv').drop(['date','Date','Name'],axis=1), 'comp': 'JNPR'})\n",
    "main_df.append({'df': pd.read_csv('./Combining Stock and Twitter Data/MyDrive/MSFTStock_Sentiment_6M.csv').drop(['date','Date','Name'],axis=1), 'comp': 'MSFT'})\n",
    "main_df.append({'df': pd.read_csv('./Combining Stock and Twitter Data/MyDrive/ORCLStock_Sentiment_6M.csv').drop(['date','Date','Name'],axis=1), 'comp': 'ORCL'})\n",
    "main_df.append({'df': pd.read_csv('./Combining Stock and Twitter Data/MyDrive/PfizerStock_Sentiment_6M.csv').drop(['date','Date','Name'],axis=1), 'comp': 'PFIZER'})\n",
    "main_df.append({'df': pd.read_csv('./Combining Stock and Twitter Data/MyDrive/TGTStock_Sentiment_6M.csv').drop(['date','Date','Name'],axis=1), 'comp': 'TGT'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1682,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalers_stock = []\n",
    "for i in range(len(main_df)):\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    main_df[i]['df'][main_df[i]['df'].columns] = scaler.fit_transform(main_df[i]['df'][main_df[i]['df'].columns])\n",
    "    scalers_stock.append({'scaler': scaler, 'comp': main_df[i]['comp']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1683,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.losses import MeanSquaredLogarithmicError, MeanSquaredError\n",
    "from keras.layers import Dense, LSTM, Dropout, Concatenate, BatchNormalization\n",
    "from tensorflow.keras.saving import register_keras_serializable\n",
    "@register_keras_serializable(package=\"MyLoss\")\n",
    "def MyLoss(y_true, y_pred):\n",
    "    msle = MeanSquaredLogarithmicError()(y_true[:,0], y_pred[:,0])\n",
    "    mse = MeanSquaredError()(y_true[:,1],y_pred[:,1])\n",
    "    return  msle + mse\n",
    "\n",
    "@register_keras_serializable(package='MyModel')\n",
    "class MyModel(Model):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.lstm1 = LSTM(units=50, return_sequences=True,\n",
    "                          input_shape=[None,30,13])\n",
    "        self.bn1 = BatchNormalization()\n",
    "        self.dropout1 = Dropout(0.2)\n",
    "\n",
    "        self.lstm2 = LSTM(units=60, return_sequences=True)\n",
    "        self.bn2 = BatchNormalization()\n",
    "        self.dropout2 = Dropout(0.3)\n",
    "\n",
    "        self.lstm3 = LSTM(units=70, return_sequences=True)\n",
    "        self.bn3 = BatchNormalization()\n",
    "        self.dropout3 = Dropout(0.4)\n",
    "\n",
    "        self.lstm4 = LSTM(units=80)\n",
    "        self.bn4 = BatchNormalization()\n",
    "        self.dropout4 = Dropout(0.5)\n",
    "\n",
    "        self.dense1_1 = Dense(20)\n",
    "        self.dense2_1 = Dense(1)\n",
    "\n",
    "        self.dense1_2 = Dense(20)\n",
    "        self.dense2_2 = Dense(1)\n",
    "        self.concat = Concatenate(axis=-1)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        enc = self.lstm1(inputs)\n",
    "        enc = self.bn1(enc)\n",
    "        enc = self.dropout1(enc)\n",
    "\n",
    "        enc = self.lstm2(enc)\n",
    "        enc = self.bn2(enc)\n",
    "        enc = self.dropout2(enc)\n",
    "\n",
    "        enc = self.lstm3(enc)\n",
    "        enc = self.bn3(enc)\n",
    "        enc = self.dropout3(enc)\n",
    "\n",
    "        enc = self.lstm4(enc)\n",
    "        enc = self.bn4(enc)\n",
    "        enc = self.dropout4(enc)\n",
    "\n",
    "        out1 = self.dense1_1(enc)\n",
    "        out1 = self.dense2_1(out1)\n",
    "\n",
    "        out2 = self.dense1_2(enc)\n",
    "        out2 = self.dense2_2(out2)\n",
    "\n",
    "        out = self.concat([out1, out2])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1684,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def makeNextDayVector(filtered_df, todays_date, stock, comp_name):\n",
    "\n",
    "\n",
    "    filtered_df['diff']=filtered_df['high']-filtered_df['low']\n",
    "    filtered_df['exp']=(filtered_df['open']+filtered_df['close'])/2\n",
    "\n",
    "\n",
    "    loaded_model = load_model('model.keras')\n",
    "\n",
    "    curr_row = filtered_df[filtered_df['Date'] == todays_date]\n",
    "    curr_row.drop(['date', 'Date', 'Name'], axis=1, inplace=True)\n",
    "    filtered_df.drop(['date', 'Date', 'Name'], axis=1, inplace=True)\n",
    "    curr_stock_value = curr_row['open'].iloc[0]\n",
    "\n",
    "    # find scaler\n",
    "    scaler = MinMaxScaler()\n",
    "    for dict in scalers_stock:\n",
    "        if dict['comp'] == comp_name:\n",
    "            scaler = dict['scaler']\n",
    "            break\n",
    "\n",
    "    filtered_df[filtered_df.columns] = scaler.fit_transform(filtered_df[filtered_df.columns])\n",
    "\n",
    "    predicted_values = pd.DataFrame()\n",
    "\n",
    "    predicted_values[['open', 'high', 'low', 'volume', 'close', 'Positve', 'Negative','Neutral', 'Total', 'NeutralPos', 'NeutralNeg']] = 0\n",
    "\n",
    "    predicted_values[['diff', 'exp']] = loaded_model.predict(np.array([filtered_df.values]).astype(float))\n",
    "\n",
    "    # predicted_values=scaler.inverse_transform(predicted_values)\n",
    "    print(predicted_values.columns)\n",
    "\n",
    "    predicted_values[predicted_values.columns] = scaler.inverse_transform(predicted_values)\n",
    "\n",
    "\n",
    "\n",
    "    predicted_values.drop(['open', 'high', 'low', 'volume', 'close', 'Positve', 'Negative','Neutral', 'Total', 'NeutralPos', 'NeutralNeg'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "    expected_value = predicted_values['exp'].iloc[0]\n",
    "    error = predicted_values['diff'].iloc[0]\n",
    "\n",
    "    percen_portfolio = stock['Percentage of portfolio']\n",
    "    percen_sector = stock['Percentage of sector']\n",
    "    sector = stock['Sector of Stock']\n",
    "\n",
    "    positives = curr_row['Positve'].iloc[0]\n",
    "    negatives = curr_row['Negative'].iloc[0]\n",
    "    total = curr_row['Total'].iloc[0]\n",
    "    neutral = curr_row['Neutral'].iloc[0]\n",
    "    neutral_pos = curr_row['NeutralPos'].iloc[0]\n",
    "    neutral_neg = curr_row['NeutralNeg'].iloc[0]\n",
    "\n",
    "\n",
    "\n",
    "    stock_vect = []\n",
    "    stock_vect.append(curr_stock_value)\n",
    "    stock_vect.append(expected_value)\n",
    "    stock_vect.append(error)\n",
    "    stock_vect.append(percen_portfolio)\n",
    "    stock_vect.append(percen_sector)\n",
    "    stock_vect.append(positives)\n",
    "    stock_vect.append(negatives)\n",
    "    stock_vect.append(total)\n",
    "    stock_vect.append(neutral)\n",
    "    stock_vect.append(neutral_pos)\n",
    "    stock_vect.append(neutral_neg)\n",
    "\n",
    "    # add posi negi from filtered data in stock vector\n",
    "\n",
    "    # stock_vect.append(sector)\n",
    "\n",
    "\n",
    "    return stock_vect\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User input vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1685,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Percentage of portfolio': 0.5,\n",
       "  'Percentage of sector': 15.56,\n",
       "  'Sector of Stock': 'IT',\n",
       "  'comp': 'AMZN'},\n",
       " {'Percentage of portfolio': 4.5,\n",
       "  'Percentage of sector': 7.8,\n",
       "  'Sector of Stock': 'IT',\n",
       "  'comp': 'MSFT'},\n",
       " {'Percentage of portfolio': 7.5,\n",
       "  'Percentage of sector': 18.26,\n",
       "  'Sector of Stock': 'Health',\n",
       "  'comp': 'AAPL'},\n",
       " {'Percentage of portfolio': 16.5,\n",
       "  'Percentage of sector': 10.26,\n",
       "  'Sector of Stock': 'Health',\n",
       "  'comp': 'PFIZER'}]"
      ]
     },
     "execution_count": 1685,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = []\n",
    "\n",
    "todays_date = '1/8/2018'\n",
    "list_of_stocks = []\n",
    "list_of_stocks.append({'Percentage of portfolio': 0.5, 'Percentage of sector': 15.56, 'Sector of Stock': 'IT', 'comp': 'AMZN'});\n",
    "list_of_stocks.append({'Percentage of portfolio': 4.5, 'Percentage of sector': 7.8, 'Sector of Stock': 'IT', 'comp': 'MSFT'});\n",
    "list_of_stocks.append({'Percentage of portfolio': 7.5, 'Percentage of sector': 18.26, 'Sector of Stock': 'Health', 'comp': 'AAPL'});\n",
    "list_of_stocks.append({'Percentage of portfolio': 16.5, 'Percentage of sector': 10.26, 'Sector of Stock': 'Health', 'comp': 'PFIZER'});\n",
    "list_of_stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1686,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/satvikv/apps/miniconda/miniconda3/envs/rec_proj/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/tmp/ipykernel_4330/2993926521.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  curr_row.drop(['date', 'Date', 'Name'], axis=1, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 286ms/step\n",
      "Index(['open', 'high', 'low', 'volume', 'close', 'Positve', 'Negative',\n",
      "       'Neutral', 'Total', 'NeutralPos', 'NeutralNeg', 'diff', 'exp'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/satvikv/apps/miniconda/miniconda3/envs/rec_proj/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/tmp/ipykernel_4330/2993926521.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  curr_row.drop(['date', 'Date', 'Name'], axis=1, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 374ms/step\n",
      "Index(['open', 'high', 'low', 'volume', 'close', 'Positve', 'Negative',\n",
      "       'Neutral', 'Total', 'NeutralPos', 'NeutralNeg', 'diff', 'exp'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/satvikv/apps/miniconda/miniconda3/envs/rec_proj/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/tmp/ipykernel_4330/2993926521.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  curr_row.drop(['date', 'Date', 'Name'], axis=1, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 317ms/step\n",
      "Index(['open', 'high', 'low', 'volume', 'close', 'Positve', 'Negative',\n",
      "       'Neutral', 'Total', 'NeutralPos', 'NeutralNeg', 'diff', 'exp'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/satvikv/apps/miniconda/miniconda3/envs/rec_proj/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/tmp/ipykernel_4330/2993926521.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  curr_row.drop(['date', 'Date', 'Name'], axis=1, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 288ms/step\n",
      "Index(['open', 'high', 'low', 'volume', 'close', 'Positve', 'Negative',\n",
      "       'Neutral', 'Total', 'NeutralPos', 'NeutralNeg', 'diff', 'exp'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "next_vectors = []\n",
    "for i in range(len(list_of_stocks)):\n",
    "    if(list_of_stocks[i]['comp'] == 'AMZN'):\n",
    "        df = pd.read_csv('./Combining Stock and Twitter Data/MyDrive/AmazonStock_Sentiment_6M.csv');\n",
    "        filtered_df = df[df['Date'].replace('/', '') <= todays_date.replace('/', '')].tail(30)\n",
    "        next_vectors.append({'next_day_vector': makeNextDayVector(filtered_df, todays_date, list_of_stocks[i], 'AMZN'), 'comp': 'AMZN'})\n",
    "    elif(list_of_stocks[i]['comp'] == 'AAPL'):\n",
    "        df = pd.read_csv('./Combining Stock and Twitter Data/MyDrive/AAPLStock_sentiment_6M.csv')\n",
    "        filtered_df = df[df['Date'].replace('/', '') <= todays_date.replace('/', '')].tail(30)\n",
    "        next_vectors.append({'next_day_vector': makeNextDayVector(filtered_df, todays_date, list_of_stocks[i], 'AAPL'), 'comp': 'AAPL'})\n",
    "    elif(list_of_stocks[i]['comp'] == 'MSFT'):\n",
    "        df = pd.read_csv('./Combining Stock and Twitter Data/MyDrive/MSFTStock_Sentiment_6M.csv')\n",
    "        filtered_df = df[df['Date'].replace('/', '') <= todays_date.replace('/', '')].tail(30)\n",
    "        next_vectors.append({'next_day_vector': makeNextDayVector(filtered_df, todays_date, list_of_stocks[i], 'MSFT'), 'comp': 'MSFT'})\n",
    "    elif(list_of_stocks[i]['comp'] == 'PFIZER'):\n",
    "        df = pd.read_csv('./Combining Stock and Twitter Data/MyDrive/PfizerStock_Sentiment_6M.csv')\n",
    "        filtered_df = df[df['Date'].replace('/', '') <= todays_date.replace('/', '')].tail(30)\n",
    "        next_vectors.append({'next_day_vector': makeNextDayVector(filtered_df, todays_date, list_of_stocks[i], 'PFIZER'), 'comp': 'PFIZER'})\n",
    "    elif(list_of_stocks[i]['comp'] == 'CSCO'):\n",
    "        df = pd.read_csv('./Combining Stock and Twitter Data/MyDrive/CSCOStock_Sentiment_6M.csv')\n",
    "        filtered_df = df[df['Date'].replace('/', '') <= todays_date.replace('/', '')].tail(30)\n",
    "        next_vectors.append({'next_day_vector': makeNextDayVector(filtered_df, todays_date, list_of_stocks[i], 'CSCO'), 'comp': 'CSCO'})\n",
    "    elif(list_of_stocks[i]['comp'] == 'IBM'):\n",
    "        df = pd.read_csv('./Combining Stock and Twitter Data/MyDrive/IBMStock_Sentiment_6M.csv')\n",
    "        filtered_df = df[df['Date'].replace('/', '') <= todays_date.replace('/', '')].tail(30)\n",
    "        next_vectors.append({'next_day_vector': makeNextDayVector(filtered_df, todays_date, list_of_stocks[i], 'IBM'), 'comp': 'IBM'})\n",
    "    elif(list_of_stocks[i]['comp'] == 'JNJ'):\n",
    "        df = pd.read_csv('./Combining Stock and Twitter Data/MyDrive/JNJStock_Sentiment_6M.csv')\n",
    "        filtered_df = df[df['Date'].replace('/', '') <= todays_date.replace('/', '')].tail(30)\n",
    "        next_vectors.append({'next_day_vector': makeNextDayVector(filtered_df, todays_date, list_of_stocks[i], 'JNJ'), 'comp': 'JNJ'})\n",
    "    elif(list_of_stocks[i]['comp'] == 'JNPR'):\n",
    "        df = pd.read_csv('./Combining Stock and Twitter Data/MyDrive/JNPRStock_Sentiment_6M.csv')\n",
    "        filtered_df = df[df['Date'].replace('/', '') <= todays_date.replace('/', '')].tail(30)\n",
    "        next_vectors.append({'next_day_vector': makeNextDayVector(filtered_df, todays_date, list_of_stocks[i], 'JNPR'), 'comp': 'JNPR'})\n",
    "    elif(list_of_stocks[i]['comp'] == 'ORCL'):\n",
    "        df = pd.read_csv('./Combining Stock and Twitter Data/MyDrive/ORCLStock_Sentiment_6M.csv')\n",
    "        filtered_df = df[df['Date'].replace('/', '') <= todays_date.replace('/', '')].tail(30)\n",
    "        next_vectors.append({'next_day_vector': makeNextDayVector(filtered_df, todays_date, list_of_stocks[i], 'ORCL'), 'comp': 'ORCL'})\n",
    "    elif(list_of_stocks[i]['comp'] == 'TGT'):\n",
    "        df = pd.read_csv('./Combining Stock and Twitter Data/MyDrive/TGTStock_Sentiment_6M.csv')\n",
    "        filtered_df = df[df['Date'].replace('/', '') <= todays_date.replace('/', '')].tail(30)\n",
    "        next_vectors.append({'next_day_vector': makeNextDayVector(filtered_df, todays_date, list_of_stocks[i], 'TGT'), 'comp': 'TGT'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1687,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'next_day_vector': [1236.0,\n",
       "   1395.839195690751,\n",
       "   25.248018814325256,\n",
       "   0.5,\n",
       "   15.56,\n",
       "   43.75523889,\n",
       "   6.370494552,\n",
       "   1193,\n",
       "   49.87426655,\n",
       "   43.75523889,\n",
       "   18.5131766],\n",
       "  'comp': 'AMZN'},\n",
       " {'next_day_vector': [88.2,\n",
       "   93.4781572419405,\n",
       "   1.5348345750689567,\n",
       "   4.5,\n",
       "   7.8,\n",
       "   43.25955734,\n",
       "   18.5110664,\n",
       "   497,\n",
       "   38.22937626,\n",
       "   43.25955734,\n",
       "   27.49427691],\n",
       "  'comp': 'MSFT'},\n",
       " {'next_day_vector': [174.35,\n",
       "   168.18254580177367,\n",
       "   1.6677195708751704,\n",
       "   7.5,\n",
       "   18.26,\n",
       "   45.12110727,\n",
       "   10.7266436,\n",
       "   1445,\n",
       "   44.15224913,\n",
       "   45.12110727,\n",
       "   17.41256408],\n",
       "  'comp': 'AAPL'},\n",
       " {'next_day_vector': [36.72,\n",
       "   37.734094686508186,\n",
       "   1.0126724314689688,\n",
       "   16.5,\n",
       "   10.26,\n",
       "   28.08988764,\n",
       "   6.460674157,\n",
       "   356,\n",
       "   65.4494382,\n",
       "   28.57739951,\n",
       "   6.460674157],\n",
       "  'comp': 'PFIZER'}]"
      ]
     },
     "execution_count": 1687,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1688,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/satvikv/apps/miniconda/miniconda3/envs/rec_proj/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/satvikv/apps/miniconda/miniconda3/envs/rec_proj/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/satvikv/apps/miniconda/miniconda3/envs/rec_proj/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/satvikv/apps/miniconda/miniconda3/envs/rec_proj/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "for i in next_vectors:\n",
    "    scaler = MinMaxScaler()\n",
    "    for dict in scalers_decisions:\n",
    "        if dict['comp'] == i['comp']:\n",
    "            scaler = dict['scaler']\n",
    "            break\n",
    "\n",
    "    normalized_array = scaler.transform([i['next_day_vector']])\n",
    "    normalized_list = normalized_array.flatten()\n",
    "    i['next_day_vector'] = normalized_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating Distance from Cluster Centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1689,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroid_decision = {}\n",
    "for i in range(len(centroids)):\n",
    "\tif centroids[i, -3] == max(centroids[i, -3], centroids[i, -2], centroids[i, -1]):\n",
    "\t\tcentroid_decision[i] = \"Buy\"\n",
    "\telif centroids[i, -2] == max(centroids[i, -3], centroids[i, -2], centroids[i, -1]):\n",
    "\t\tcentroid_decision[i] = \"Keep\"\n",
    "\telif centroids[i, -1] == max(centroids[i, -3], centroids[i, -2], centroids[i, -1]):\n",
    "\t\tcentroid_decision[i] = \"Sell\"\n",
    "\telse:\n",
    "\t\tcentroid_decision[i] = \"Keep\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1690,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Keep',\n",
       " 1: 'Buy',\n",
       " 2: 'Sell',\n",
       " 3: 'Keep',\n",
       " 4: 'Sell',\n",
       " 5: 'Buy',\n",
       " 6: 'Sell',\n",
       " 7: 'Buy',\n",
       " 8: 'Keep',\n",
       " 9: 'Keep'}"
      ]
     },
     "execution_count": 1690,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centroid_decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1691,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids_without_decision = centroids[:,:-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1692,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_from_centroid = []\n",
    "for j in range(len(next_vectors)):\n",
    "\tcurrent_distances = []\n",
    "\tfor i in range(centroids_without_decision.shape[0]):\n",
    "\t\tcurrent_distances.append(np.linalg.norm(next_vectors[j]['next_day_vector'] - centroids_without_decision[i]))\n",
    "\tdistance_from_centroid.append(current_distances)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1693,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1.0224343577988908,\n",
       "  0.8002561101122951,\n",
       "  1.0170127333501993,\n",
       "  1.0789053222385216,\n",
       "  0.8199402111289532,\n",
       "  0.6788999463562865,\n",
       "  0.7651604132688716,\n",
       "  1.029716871147987,\n",
       "  0.8237890692744544,\n",
       "  0.7875953656869792],\n",
       " [1.5556288888679808,\n",
       "  1.1917284506743058,\n",
       "  1.4160551760144684,\n",
       "  1.3967202950283337,\n",
       "  1.2470074319753643,\n",
       "  1.0382417951924774,\n",
       "  0.9927128879358923,\n",
       "  1.4927851600210833,\n",
       "  1.1885957284776656,\n",
       "  1.0022809935716464],\n",
       " [1.5212610818132384,\n",
       "  1.2302722653158134,\n",
       "  1.3617884543654397,\n",
       "  1.0296338854357714,\n",
       "  1.210188288869231,\n",
       "  1.2390916851168834,\n",
       "  1.233468094877091,\n",
       "  1.3934669126436898,\n",
       "  1.223379502200702,\n",
       "  1.2735437008749289],\n",
       " [3.3405652253703453,\n",
       "  3.195006750910928,\n",
       "  3.2099575775662696,\n",
       "  2.957357824787641,\n",
       "  3.2188270166843886,\n",
       "  3.2520498435348246,\n",
       "  3.1895037327108047,\n",
       "  3.2150338735543578,\n",
       "  3.1813190161251934,\n",
       "  3.2577977609582467]]"
      ]
     },
     "execution_count": 1693,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance_from_centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1694,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "\n",
    "for i in range(len(distance_from_centroid)):\n",
    "    min_index = 0\n",
    "    for j in range(len(distance_from_centroid[i])):\n",
    "        if(distance_from_centroid[i][j] < distance_from_centroid[i][min_index]):\n",
    "            min_index = j\n",
    "\n",
    "    centroid = centroid_decision[min_index]\n",
    "    if centroid not in results:\n",
    "        results[centroid] = []  # Initialize empty list if centroid not in results\n",
    "    results[centroid].append(next_vectors[i]['comp'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1696,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Buy': ['AMZN'], 'Sell': ['MSFT'], 'Keep': ['AAPL', 'PFIZER']}"
      ]
     },
     "execution_count": 1696,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rec_proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
